# ğŸ­ Casting Quality Control â€” IA Week (Groupe 6)

> SystÃ¨me de contrÃ´le qualitÃ© par vision artificielle pour piÃ¨ces de fonderie.  
> Classifie automatiquement les piÃ¨ces en **Conforme âœ…** ou **DÃ©fectueuse âŒ** grÃ¢ce Ã  un pipeline **ResNet50 + SVM**.

![Python](https://img.shields.io/badge/Python-3.12-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-latest-009688)
![PyTorch](https://img.shields.io/badge/PyTorch-latest-ee4c2c)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED)

---

## ğŸ“‹ Table des matiÃ¨res

- [PrÃ©sentation](#-prÃ©sentation)
- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Architecture](#-architecture)
- [PrÃ©requis](#-prÃ©requis)
- [Installation & Lancement](#-installation--lancement)
- [Utilisation](#-utilisation)
- [Structure du projet](#-structure-du-projet)
- [API Endpoints](#-api-endpoints)
- [Pipeline ML](#-pipeline-ml)
- [Configuration](#-configuration)
- [GPU (optionnel)](#-gpu-optionnel)
- [DÃ©pannage](#-dÃ©pannage)
- [Ã‰quipe](#-Ã©quipe)

---

## ğŸ¯ PrÃ©sentation

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre de l'**IA Week**. Il s'agit d'une application web qui simule une **chaÃ®ne de production industrielle** avec un convoyeur animÃ©. Les images de piÃ¨ces de fonderie sont analysÃ©es par un modÃ¨le d'intelligence artificielle qui dÃ©tecte automatiquement les dÃ©fauts de fabrication.

**Le pipeline ML combine :**
1. **ResNet50** (rÃ©seau de neurones profond prÃ©-entraÃ®nÃ©) pour l'extraction de caractÃ©ristiques visuelles
2. **SVM** (Support Vector Machine) pour la classification binaire OK/DÃ©faut

---

## âœ¨ FonctionnalitÃ©s

- ğŸ” **Classification automatique** â€” DÃ©tection de dÃ©fauts sur piÃ¨ces de fonderie
- ğŸ­ **Convoyeur animÃ©** â€” Interface industrielle avec animation GSAP du tri des piÃ¨ces
- ï¿½ **Recherche de similaritÃ©** â€” Trouve les 10 images les plus proches dans le dataset pour chaque piÃ¨ce analysÃ©e
- ğŸ“Š **Statistiques en temps rÃ©el** â€” Taux de conformitÃ©, compteurs, historique
- ğŸ–±ï¸ **Drag & Drop** â€” Glissez-dÃ©posez vos images pour les analyser
- ğŸ“‹ **File d'attente** â€” Traitement sÃ©quentiel avec suivi visuel
- ğŸ  **Carousel interactif** â€” Navigation horizontale dans les rÃ©sultats de similaritÃ© avec zoom au clic
- ğŸ”’ **Authentification** â€” Page de connexion sÃ©curisÃ©e
- ğŸ³ **DockerisÃ©** â€” DÃ©ploiement en un seul commande
- â™»ï¸ **Live Reload** â€” Modification du code sans rebuild en dÃ©veloppement
- ğŸ““ **Notebook d'entraÃ®nement** â€” Encodage du dataset et benchmark des mÃ©triques de distance

---

## ğŸ—ï¸ Architecture

L'application est composÃ©e de **2 services Docker** communiquant via un rÃ©seau interne :

```
  ğŸŒ Navigateur (port 80)
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚     FRONTEND     â”‚  proxy   â”‚       BACKEND        â”‚
  â”‚  FastAPI         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  FastAPI              â”‚
  â”‚  HTML/CSS/JS     â”‚  /api/*  â”‚  PyTorch + SVM       â”‚
  â”‚  (port 3000)     â”‚          â”‚  (port 8000)         â”‚
  â”‚                  â”‚          â”‚                      â”‚
  â”‚  â€¢ Convoyeur     â”‚          â”‚  /api/classify       â”‚
  â”‚  â€¢ SimilaritÃ©    â”‚          â”‚  /api/similar        â”‚
  â”‚                  â”‚          â”‚  /api/images/*       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚           â”‚
                             â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚ /models â”‚ â”‚/casting_data â”‚
                             â”‚svm_modelâ”‚ â”‚ (images du   â”‚
                             â”‚ scaler  â”‚ â”‚  dataset)    â”‚
                             â”‚features â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ _datasetâ”‚
                             â”‚  .npz   â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> ğŸ“– Pour plus de dÃ©tails, voir [architecture.md](architecture.md)

---

## ğŸ“¦ PrÃ©requis

- [Docker](https://docs.docker.com/get-docker/) (â‰¥ 20.10)
- [Docker Compose](https://docs.docker.com/compose/install/) (â‰¥ 2.0)
- **~3 Go d'espace disque** (images Docker + modÃ¨les PyTorch)

> **Note :** Aucune installation Python locale n'est nÃ©cessaire, tout tourne dans Docker.

---

## ğŸš€ Installation & Lancement

### 1. Cloner le projet

```bash
git clone <url-du-repo>
cd "Solution Ia Week"
```

### 2. VÃ©rifier les modÃ¨les

Assurez-vous que les fichiers de modÃ¨les sont prÃ©sents dans le dossier `models/` :

```
models/
â”œâ”€â”€ resnet50_extractor.pth    # Poids ResNet50 (extraction de features)
â”œâ”€â”€ svm_model.joblib          # ModÃ¨le SVM entraÃ®nÃ©
â”œâ”€â”€ scaler.joblib             # StandardScaler (normalisation des features)
â”œâ”€â”€ features_dataset.npz      # Vecteurs de features du dataset (gÃ©nÃ©rÃ© par ia_training)
â””â”€â”€ similarity_config.json    # Configuration de la mÃ©trique de distance (gÃ©nÃ©rÃ© par ia_training)
```

> âš ï¸ Les 3 premiers fichiers sont gÃ©nÃ©rÃ©s lors de l'entraÃ®nement initial.
> Les 2 derniers sont gÃ©nÃ©rÃ©s par le notebook `ia_training.ipynb` (voir section suivante).

### 3. GÃ©nÃ©rer le dataset de similaritÃ© (optionnel mais requis pour `/similarity.html`)

```bash
# CrÃ©er un environnement Python 3.12 et exÃ©cuter le notebook
python3.12 -m venv .venv312
source .venv312/bin/activate
pip install torch==2.9.0+cpu torchvision==0.24.0+cpu --index-url https://download.pytorch.org/whl/cpu
pip install scikit-learn==1.6.1 scipy joblib numpy Pillow matplotlib
jupyter notebook ia_training.ipynb
```

Le notebook va :
1. Encoder toutes les images de `casting_data/` en vecteurs 2048-dim
2. Benchmarker plusieurs mÃ©triques de distance (cosinus, euclidienne, Manhattan, etc.)
3. Sauvegarder `models/features_dataset.npz` et `models/similarity_config.json`

### 4. Lancer l'application

```bash
docker compose up --build
```

Au premier lancement, Docker va :
1. TÃ©lÃ©charger les images Python (3.12 pour le backend, 3.11 pour le frontend)
2. Installer les dÃ©pendances (PyTorch, scikit-learn, etc.)
3. Charger les modÃ¨les ML
4. DÃ©marrer les deux serveurs

### 4. AccÃ©der Ã  l'application

Ouvrez votre navigateur sur : **[http://localhost](http://localhost)**

### 5. ArrÃªter l'application

```bash
docker compose down
```

---

## ğŸ–¥ï¸ Utilisation

### Connexion

| Champ         | Valeur           |
|---------------|------------------|
| **Identifiant** | `demo_client`  |
| **Mot de passe** | `iaweekgroup6` |

### Analyser des piÃ¨ces

1. **Connectez-vous** avec les identifiants ci-dessus
2. **Glissez-dÃ©posez** des images de piÃ¨ces dans la zone de chargement (panneau gauche)
3. **Observez** le convoyeur animÃ© traiter chaque piÃ¨ce :
   - La piÃ¨ce arrive sur le tapis roulant
   - La camÃ©ra IA scanne la piÃ¨ce
   - Le rÃ©sultat s'affiche (Conforme âœ… ou DÃ©fectueuse âŒ)
   - Le bras de tri envoie la piÃ¨ce dans le bon bac
4. **Consultez** les statistiques et l'historique en temps rÃ©el

### Recherche de similaritÃ©

1. **Cliquez** sur **ğŸ” SimilaritÃ©** dans le header (ou allez sur `/similarity.html`)
2. **Glissez-dÃ©posez** une image dans la zone d'upload
3. **Visualisez** le rÃ©sultat de classification (OK/DEF + confiance)
4. **Parcourez** le carousel des 10 images les plus similaires du dataset
5. **Cliquez** sur une image du carousel pour l'agrandir

### Formats d'images supportÃ©s

- JPEG / JPG
- PNG

---

## ğŸ“‚ Structure du projet

```
Solution Ia Week/
â”‚
â”œâ”€â”€ docker-compose.yml          # Orchestration des 2 services
â”œâ”€â”€ architecture.md             # Documentation de l'architecture
â”œâ”€â”€ README.md                   # Ce fichier
â”‚
â”œâ”€â”€ backend/                    # Service d'infÃ©rence ML
â”‚   â”œâ”€â”€ Dockerfile              # Image Docker du backend
â”‚   â”œâ”€â”€ main.py                 # API FastAPI (endpoints /api/*)
â”‚   â”œâ”€â”€ feature_extractor.py    # Classe ResNet50 feature extractor
â”‚   â””â”€â”€ requirements.txt        # DÃ©pendances Python backend
â”‚
â”œâ”€â”€ frontend/                   # Service web (UI + proxy)
â”‚   â”œâ”€â”€ Dockerfile              # Image Docker du frontend
â”‚   â”œâ”€â”€ main.py                 # Serveur FastAPI (proxy + static)
â”‚   â”œâ”€â”€ requirements.txt        # DÃ©pendances Python frontend
â”‚   â””â”€â”€ static/                 # Fichiers servis au navigateur
â”‚       â”œâ”€â”€ index.html          # Page principale (convoyeur)
â”‚       â”œâ”€â”€ similarity.html     # Page de recherche de similaritÃ©
â”‚       â”œâ”€â”€ login.html          # Page de connexion
â”‚       â”œâ”€â”€ style.css           # Styles (thÃ¨me industriel sombre)
â”‚       â”œâ”€â”€ conveyor.js         # Logique JS convoyeur + animations GSAP
â”‚       â””â”€â”€ similarity.js       # Logique JS recherche de similaritÃ©
â”‚
â”œâ”€â”€ models/                     # ModÃ¨les ML sÃ©rialisÃ©s
â”‚   â”œâ”€â”€ resnet50_extractor.pth  # Poids ResNet50 (extraction features)
â”‚   â”œâ”€â”€ svm_model.joblib        # SVM entraÃ®nÃ© (classification)
â”‚   â”œâ”€â”€ scaler.joblib           # StandardScaler (normalisation)
â”‚   â”œâ”€â”€ features_dataset.npz   # Vecteurs de features du dataset
â”‚   â””â”€â”€ similarity_config.json  # Config mÃ©trique de distance
â”‚
â”œâ”€â”€ casting_data/               # Dataset d'images de piÃ¨ces de fonderie
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ def_front/          # Images dÃ©fectueuses (entraÃ®nement)
â”‚   â”‚   â””â”€â”€ ok_front/           # Images conformes (entraÃ®nement)
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ def_front/          # Images dÃ©fectueuses (test)
â”‚       â””â”€â”€ ok_front/           # Images conformes (test)
â”‚
â”œâ”€â”€ ia_training.ipynb           # Notebook : encodage dataset + benchmark distances
â”‚
â””â”€â”€ exemple_dimage/             # Images d'exemple pour tester
```

---

## ğŸ”Œ API Endpoints

### `GET /api/health` â€” Ã‰tat du serveur

**RÃ©ponse :**
```json
{
  "status": "ok",
  "device": "cpu",
  "cuda_available": false,
  "svm_loaded": true,
  "scaler_loaded": true
}
```

### `POST /api/classify` â€” Classifier une image

**RequÃªte :** `multipart/form-data` avec un champ `file` (image)

```bash
curl -X POST http://localhost/api/classify \
  -F "file=@mon_image.jpg"
```

**RÃ©ponse :**
```json
{
  "label": "ok",
  "label_fr": "PiÃ¨ce Conforme âœ…",
  "color": "#22c55e",
  "confidence": 0.932,
  "inference_time_ms": 145.3,
  "filename": "mon_image.jpg"
}
```

### `POST /api/similar` â€” Recherche de similaritÃ©

**RequÃªte :** `multipart/form-data` avec un champ `file` (image)

```bash
curl -X POST http://localhost/api/similar \
  -F "file=@mon_image.jpg"
```

**RÃ©ponse :**
```json
{
  "label": "def",
  "label_fr": "PiÃ¨ce DÃ©fectueuse âŒ",
  "color": "#ef4444",
  "confidence": 0.87,
  "inference_time_ms": 152.4,
  "filename": "mon_image.jpg",
  "metric": "cosine",
  "similar": [
    {
      "rank": 1,
      "path": "test/def_front/cast_def_0_100.jpeg",
      "label": "def",
      "distance": 0.0523,
      "image_url": "/api/images/test/def_front/cast_def_0_100.jpeg"
    }
  ]
}
```

### `GET /api/images/{path}` â€” Servir une image du dataset

```bash
curl http://localhost/api/images/test/ok_front/cast_ok_0_100.jpeg --output image.jpeg
```

Retourne l'image depuis le dossier `casting_data/`. ProtÃ©gÃ© contre le path traversal.

| Champ               | Description                                    |
|---------------------|------------------------------------------------|
| `label`             | `"ok"` ou `"def"`                              |
| `label_fr`          | Label en franÃ§ais avec emoji                   |
| `color`             | Code couleur (vert = OK, rouge = dÃ©faut)       |
| `confidence`        | Score de confiance entre 0.5 et 1.0            |
| `inference_time_ms` | Temps de traitement en millisecondes            |
| `filename`          | Nom du fichier envoyÃ©                          |
| `metric`            | MÃ©trique de distance utilisÃ©e (sur `/api/similar`) |
| `similar`           | Top 10 images les plus proches (sur `/api/similar`) |

---

## ğŸ§  Pipeline ML

Le pipeline d'infÃ©rence suit 5 Ã©tapes :

```
Image â†’ Preprocessing â†’ ResNet50 (features 2048-dim) â†’ Scaler â†’ SVM â†’ OK/DEF
```

1. **Preprocessing** â€” L'image est redimensionnÃ©e Ã  224Ã—224 pixels puis normalisÃ©e avec les moyennes/Ã©carts-types d'ImageNet
2. **Feature Extraction** â€” ResNet50 prÃ©-entraÃ®nÃ© (sans la derniÃ¨re couche) extrait un vecteur de 2048 caractÃ©ristiques
3. **Scaling** â€” Le `StandardScaler` normalise les features (mÃªme transformation que l'entraÃ®nement)
4. **Classification** â€” Le SVM prÃ©dit la classe : `0` = conforme (ok), `1` = dÃ©faut (def)
5. **Confiance** â€” CalculÃ©e via la sigmoÃ¯de de la `decision_function` du SVM

### Pourquoi ResNet50 + SVM ?

- **ResNet50** est excellent pour extraire des features visuelles de haut niveau (textures, formes, motifs)
- **SVM** est efficace pour la classification binaire sur des features de haute dimension
- Cette approche est plus **lÃ©gÃ¨re Ã  entraÃ®ner** qu'un fine-tuning complet du rÃ©seau

---

## âš™ï¸ Configuration

### Variables principales (`backend/main.py`)

| Variable        | Valeur par dÃ©faut                | Description                      |
|-----------------|----------------------------------|----------------------------------|
| `MODEL_DIR`     | `/models`                        | Dossier des modÃ¨les dans Docker  |
| `IMG_SIZE`      | `224`                            | Taille des images en entrÃ©e      |
| `DEVICE`        | Auto (`cuda` si dispo, sinon `cpu`) | Device PyTorch                |
| `CLASSES`       | `["ok", "def"]`                  | Labels (index 0 = ok, 1 = dÃ©faut) |

### Proxy frontend (`frontend/main.py`)

| Variable        | Valeur                    | Description                     |
|-----------------|---------------------------|---------------------------------|
| `BACKEND_URL`   | `http://backend:8000`     | URL interne du backend Docker   |

---

## ğŸ–¥ï¸ GPU (optionnel)

Pour utiliser un **GPU NVIDIA**, dÃ©commentez le bloc dans `docker-compose.yml` :

```yaml
backend:
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
```

**PrÃ©requis :**
- Drivers NVIDIA installÃ©s sur la machine hÃ´te
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)

Sans GPU, l'application fonctionne normalement sur **CPU** (infÃ©rence un peu plus lente).

---

## ğŸ”§ DÃ©pannage

### Le backend ne dÃ©marre pas

```bash
# VÃ©rifier les logs
docker compose logs backend
```

**Causes frÃ©quentes :**
- Fichiers `models/svm_model.joblib` ou `models/scaler.joblib` manquants
- Pas assez de mÃ©moire RAM (PyTorch + ResNet50 nÃ©cessitent ~1-2 Go)

### "Backend hors ligne" dans l'interface

- Le backend met quelques secondes Ã  dÃ©marrer (chargement de ResNet50)
- VÃ©rifier que les deux conteneurs tournent : `docker compose ps`
- Consulter les logs : `docker compose logs -f`

### Erreur de classification

- VÃ©rifier que l'image est bien au format JPEG ou PNG
- L'image doit reprÃ©senter une piÃ¨ce de fonderie (le modÃ¨le est spÃ©cialisÃ©)

### Rebuild complet

```bash
docker compose down
docker compose build --no-cache
docker compose up
```

---

## ğŸ‘¥ Ã‰quipe

**IA Week â€” Groupe 6**

---

## ğŸ“„ Licence

Projet acadÃ©mique â€” IA Week.
